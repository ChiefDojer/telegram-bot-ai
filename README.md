# ğŸ¤– Telegram Bot AI

Multi-AI provider Telegram bot built with Aiogram v3. Chat with ChatGPT, Google Gemini, Claude, Grok, or your own custom LLM!

## âœ¨ Features

- ğŸ”„ **Multiple AI Providers**: Switch between different AI models on the fly
- ğŸ’¬ **Conversation Context**: Maintains chat history for coherent conversations
- ğŸ¯ **Easy Setup**: Simple configuration through environment variables
- ğŸ³ **Docker Ready**: Containerized deployment with Docker Compose
- ğŸ”Œ **Custom LLM Support**: Works with any OpenAI-compatible API (Ollama, LM Studio, etc.)

## ğŸ§  Supported AI Providers

| Provider | Models | API Key Required |
|----------|--------|------------------|
| **ChatGPT** (OpenAI) | gpt-4o-mini, gpt-4o, gpt-4-turbo | âœ… OPENAI_API_KEY |
| **Google Gemini** | gemini-1.5-flash, gemini-1.5-pro | âœ… GEMINI_API_KEY |
| **Claude** (Anthropic) | claude-3-5-sonnet, claude-3-opus | âœ… ANTHROPIC_API_KEY |
| **Grok** (xAI) | grok-beta, grok-vision-beta | âœ… XAI_API_KEY |
| **Custom LLM** | Any OpenAI-compatible API | âš™ï¸ CUSTOM_LLM_BASE_URL |

## ğŸš€ Quick Start

### 1. Prerequisites

- Python 3.11+ or Docker
- Telegram Bot Token (get from [@BotFather](https://t.me/botfather))
- At least one AI service API key

### 2. Clone and Configure

```bash
# Clone the repository
git clone <your-repo-url>
cd telegram-bot-ai

# Copy environment template
cp .env.example .env

# Edit .env and add your credentials
notepad .env  # Windows
# or
nano .env     # Linux/Mac
```

### 3. Add Your API Keys

Edit `.env` and add your credentials:

```env
# Required
BOT_TOKEN=your_telegram_bot_token

# Add at least one AI service
OPENAI_API_KEY=sk-...          # For ChatGPT
GEMINI_API_KEY=...             # For Google Gemini
ANTHROPIC_API_KEY=sk-ant-...   # For Claude
XAI_API_KEY=xai-...            # For Grok

# Optional: Custom LLM (e.g., Ollama)
CUSTOM_LLM_BASE_URL=http://localhost:11434/v1/chat/completions
CUSTOM_LLM_MODEL=llama3
```

### 4. Run with Docker (Recommended)

```bash
# Build and start
docker-compose up -d

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

### 5. Or Run with Python

```bash
# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (Linux/Mac)
source venv/bin/activate

# Install dependencies
pip install -r app/requirements.txt

# Run the bot
cd app
python main.py
```

## ğŸ“± Bot Commands

| Command | Description |
|---------|-------------|
| `/start` | Start the bot and see welcome message |
| `/ai` | Select AI provider |
| `/help` | Show available commands |
| `/status` | Check current AI configuration |
| `/clear` | Clear conversation history |
| `/about` | About this bot |

## ğŸ’¡ Usage Examples

### Basic Chat
1. Start the bot: `/start`
2. Select an AI: `/ai`
3. Send any message to chat!

### Switch AI Providers
```
You: /ai
Bot: [Shows available AI providers]
You: [Select ChatGPT]
You: Hello!
Bot: Hi! How can I help you today?
     â€” ChatGPT (gpt-4o-mini)
```

### Check Status
```
You: /status
Bot: ğŸ¤– AI Bot Status
     Current AI: ChatGPT (gpt-4o-mini)
     Configured Services: 3/5
     âœ… ChatGPT (gpt-4o-mini)
     âœ… Google Gemini (gemini-1.5-flash)
     âŒ Claude (claude-3-5-sonnet)
     âŒ Grok (grok-beta)
     âœ… Custom LLM (llama3)
     Conversation messages: 4
```

## ğŸ”§ Configuration

### AI Service Models

You can customize models by editing `app/ai_services.py`:

```python
# Change ChatGPT model
ChatGPTService(model="gpt-4o")  # Default: gpt-4o-mini

# Change Gemini model
GeminiService(model="gemini-1.5-pro")  # Default: gemini-1.5-flash

# Change Claude model
ClaudeService(model="claude-3-opus-20240229")  # Default: claude-3-5-sonnet
```

### Custom LLM Setup

#### Using Ollama
```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Pull a model
ollama pull llama3

# Configure in .env
CUSTOM_LLM_BASE_URL=http://localhost:11434/v1/chat/completions
CUSTOM_LLM_MODEL=llama3
```

#### Using LM Studio
```env
CUSTOM_LLM_BASE_URL=http://localhost:1234/v1/chat/completions
CUSTOM_LLM_MODEL=your-model-name
```

## ğŸ“ Project Structure

```
telegram-bot-ai/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # Bot entry point
â”‚   â”œâ”€â”€ handlers.py          # Command and message handlers
â”‚   â”œâ”€â”€ ai_services.py       # AI provider implementations
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â””â”€â”€ requirements-test.txt
â”œâ”€â”€ docker-compose.yml       # Docker configuration
â”œâ”€â”€ Dockerfile              # Container image definition
â””â”€â”€ .env.example            # Environment template
```

## ğŸ”’ Security Notes

- Never commit your `.env` file with real API keys
- Keep your bot token and API keys secure
- Use environment variables in production
- Regularly rotate API keys
- Monitor API usage and costs

## ğŸ› Troubleshooting

### Bot not responding
- Check if bot token is correct
- Verify at least one AI service is configured
- Check logs: `docker-compose logs -f`

### AI service not available
- Verify API key is set correctly
- Check API key permissions and quotas
- Ensure no typos in environment variable names

### Custom LLM connection issues
- Verify the base URL is accessible
- Check if the endpoint is OpenAI-compatible
- Test the endpoint manually with curl

## ğŸ“Š API Rate Limits

| Provider | Free Tier | Notes |
|----------|-----------|-------|
| OpenAI | Limited credits | Pay as you go |
| Google Gemini | 60 requests/min | Free tier available |
| Anthropic | No free tier | Pay as you go |
| xAI Grok | Beta access | Check xAI console |
| Custom LLM | Depends on setup | Self-hosted = unlimited |

## ğŸ› ï¸ Development

### Running Tests
```bash
cd app
pytest test_handlers.py
```

### Adding New AI Provider
1. Create new service class in `ai_services.py` extending `AIService`
2. Implement required methods: `generate_response()`, `is_available()`, `name`
3. Add to `AIServiceManager.services` dictionary
4. Update documentation

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“§ Support

For issues and questions:
- Open an issue on GitHub
- Check existing documentation
- Review logs for error messages

## ğŸ™ Acknowledgments

- [Aiogram](https://github.com/aiogram/aiogram) - Telegram Bot framework
- [OpenAI](https://openai.com/) - ChatGPT API
- [Google](https://ai.google.dev/) - Gemini API
- [Anthropic](https://www.anthropic.com/) - Claude API
- [xAI](https://x.ai/) - Grok API

---

Built with â¤ï¸ using Python and Aiogram v3
